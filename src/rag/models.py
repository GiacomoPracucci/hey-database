from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from src.models.vector_store import (
    TableSearchResult,
    ColumnSearchResult,
    QuerySearchResult,
)


@dataclass
class RAGContext:
    """
    Container class for passing data between RAG pipeline stages.

    This class maintains the state of the RAG process, accumulating
    and transforming data as it passes through the pipeline stages.
    Each strategy in the pipeline can read from and write to this context.
    """

    # Original user query
    original_query: str

    # Processed query (may be rewritten or enhanced)
    processed_query: Optional[str] = None

    # Retrieved relevant tables from vector store
    retrieved_tables: List[TableSearchResult] = field(default_factory=list)

    # Retrieved relevant columns from vector store
    retrieved_columns: List[ColumnSearchResult] = field(default_factory=list)

    # Retrieved relevant previous queries from vector store
    retrieved_queries: List[QuerySearchResult] = field(default_factory=list)

    # Processed context to be included in the prompt
    processed_context: Optional[str] = None

    # The final prompt to be sent to the LLM
    final_prompt: Optional[str] = None

    # The LLM's response
    llm_response: Optional[str] = None

    # The final processed response to be sent to the user
    final_response: Optional[Dict[str, Any]] = None

    # Metadata and debug information
    metadata: Dict[str, Any] = field(default_factory=dict)

    def add_metadata(self, key: str, value: Any) -> None:
        """
        Add metadata information to the context.

        Args:
            key: Metadata key
            value: Metadata value
        """
        self.metadata[key] = value


@dataclass
class RAGResponse:
    """
    Response format for the RAG system.

    This class defines the structure of the response returned
    to the user after the RAG pipeline has been executed.
    """

    # Whether the RAG process was successful
    success: bool

    # The SQL query generated by the LLM (if applicable)
    query: Optional[str] = None

    # Explanation of the query
    explanation: Optional[str] = None

    # Query execution results
    results: Optional[List[Dict[str, Any]]] = None

    # Preview data for display
    preview: Optional[List[Dict[str, Any]]] = None

    # Error message if any
    error: Optional[str] = None

    # Whether the response was retrieved from vector store
    from_vector_store: bool = False

    # The original user question
    original_question: Optional[str] = None

    # Additional metadata about the RAG process
    metadata: Dict[str, Any] = field(default_factory=dict)
